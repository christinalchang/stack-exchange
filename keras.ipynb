{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "#import re\n",
    "#import nltk\n",
    "#import nltk.corpus\n",
    "import numpy as np\n",
    "#from nltk.corpus import wordnet\n",
    "#import matplotlib.pyplot as plt\n",
    "#from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#from sklearn.metrics.pairwise import cosine_similarity\n",
    "#from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data for bio\n",
    "df_questions = pd.read_pickle(\"./sta-141c-classify/cleaned_trim/biology_trim_clean.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rnase contamination rna base experiment prevent anyone suggestion prevent rnase contamination work rna tend issue degradation regardless whether use depc treat rnase free water filter pipette tip</td>\n",
       "      <td>[rna, biochemistry]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lymphocyte size cluster two group tortora write principle anatomy physiology lymphocyte may small μm diameter large μm range quite close others take mean lymphocytes size cluster two group way say lymphocyte μm</td>\n",
       "      <td>[immunology, cell-biology, hematology]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                 text  \\\n",
       "0                 rnase contamination rna base experiment prevent anyone suggestion prevent rnase contamination work rna tend issue degradation regardless whether use depc treat rnase free water filter pipette tip   \n",
       "1  lymphocyte size cluster two group tortora write principle anatomy physiology lymphocyte may small μm diameter large μm range quite close others take mean lymphocytes size cluster two group way say lymphocyte μm   \n",
       "\n",
       "                                     tags  \n",
       "0                     [rna, biochemistry]  \n",
       "1  [immunology, cell-biology, hematology]  "
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make tags column into list of tags\n",
    "split_list = [tags.split(\" \") for tags in list(df_questions['tags'])]\n",
    "df_questions['tags'] = split_list\n",
    "df_questions.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reduce tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split_list = [tags.split(\" \") for tags in list(df_questions['tags'])]\n",
    "split = [item for sublist in split_list for item in sublist]\n",
    "#unique = list(set(split))\n",
    "df_tags = pd.DataFrame(split)\n",
    "df_tags.columns = ['Tag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count             100\n",
       "unique            100\n",
       "top       ornithology\n",
       "freq                1\n",
       "Name: Tag, dtype: object"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_tags = df_tags.groupby(\"Tag\", sort='count').size().reset_index(name='count')\n",
    "grouped_tags.Tag.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unique = list(set(split))\n",
    "#len(unique)\n",
    "#-------\n",
    "\n",
    "num_classes = 100\n",
    "grouped_tags = df_tags.groupby(\"Tag\").size().reset_index(name='count')\n",
    "most_common_tags = grouped_tags.nlargest(num_classes, columns=\"count\")\n",
    "df_tags.Tag = df_tags.Tag.apply(lambda tag : tag if tag in most_common_tags.Tag.values else None)\n",
    "df_tags = df_tags.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['evolution', 'mitochondria', 'chloroplasts']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only keep the tags in the top 100\n",
    "\n",
    "# list of unique tags\n",
    "unique = list(set(df_tags.Tag))\n",
    "tmp = df_questions.tags[5]\n",
    "print(tmp)\n",
    "\n",
    "def tags_in_100(i, unique):\n",
    "    \"Input list of tags and top 100 tags. Return words in the original list that are also in top 100.\"\n",
    "    values = [x for x in i if x in unique]\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>top100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[rna, biochemistry]</td>\n",
       "      <td>[rna, biochemistry]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[immunology, cell-biology, hematology]</td>\n",
       "      <td>[immunology, cell-biology, hematology]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[dna, biochemistry, molecular-biology]</td>\n",
       "      <td>[dna, biochemistry, molecular-biology]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[neuroscience, synapses]</td>\n",
       "      <td>[neuroscience]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[molecular-genetics, gene-expression, experimental-design]</td>\n",
       "      <td>[molecular-genetics, gene-expression, experimental-design]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     original  \\\n",
       "0                                         [rna, biochemistry]   \n",
       "1                      [immunology, cell-biology, hematology]   \n",
       "2                      [dna, biochemistry, molecular-biology]   \n",
       "3                                    [neuroscience, synapses]   \n",
       "4  [molecular-genetics, gene-expression, experimental-design]   \n",
       "\n",
       "                                                       top100  \n",
       "0                                         [rna, biochemistry]  \n",
       "1                      [immunology, cell-biology, hematology]  \n",
       "2                      [dna, biochemistry, molecular-biology]  \n",
       "3                                              [neuroscience]  \n",
       "4  [molecular-genetics, gene-expression, experimental-design]  "
      ]
     },
     "execution_count": 515,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "only_top_100 = [tags_in_100(i, unique) for i in df_questions.tags]\n",
    "pd.DataFrame({\"original\" :np.array(df_questions.tags), \"top100\":np.array(only_top_100)}).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rnase contamination rna base experiment prevent anyone suggestion prevent rnase contamination work rna tend issue degradation regardless whether use depc treat rnase free water filter pipette tip</td>\n",
       "      <td>[rna, biochemistry]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lymphocyte size cluster two group tortora write principle anatomy physiology lymphocyte may small μm diameter large μm range quite close others take mean lymphocytes size cluster two group way say lymphocyte μm</td>\n",
       "      <td>[immunology, cell-biology, hematology]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>avoid digest dna interested sequence analyze bound dna minimize amount unbound dna get sequence digest dna unbound dna digest way maximize amount unbound dna digest</td>\n",
       "      <td>[dna, biochemistry, molecular-biology]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>condition dendritic spine form look resource information formation dendritic spine synaptogenesis especially relation new connection form daily electrotonic signalling along axon spine cause new connection make base kind spatial condition maybe electrical chemical attraction large heuristic</td>\n",
       "      <td>[neuroscience]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>reason behind choose reporter gene experiment gene interest notice within example experiment class different reporter gene choose insert near gene interest prove whether gene express example may insert gene fluorescence next gene interest know transcribe whether organism cell fluorescent degree fluoresce notice experiment multiple version one case use fluorescent gene next different gene examp...</td>\n",
       "      <td>[molecular-genetics, gene-expression, experimental-design]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                              text  \\\n",
       "0                                                                                                                                                                                                              rnase contamination rna base experiment prevent anyone suggestion prevent rnase contamination work rna tend issue degradation regardless whether use depc treat rnase free water filter pipette tip   \n",
       "1                                                                                                                                                                                               lymphocyte size cluster two group tortora write principle anatomy physiology lymphocyte may small μm diameter large μm range quite close others take mean lymphocytes size cluster two group way say lymphocyte μm   \n",
       "2                                                                                                                                                                                                                                             avoid digest dna interested sequence analyze bound dna minimize amount unbound dna get sequence digest dna unbound dna digest way maximize amount unbound dna digest   \n",
       "3                                                                                                              condition dendritic spine form look resource information formation dendritic spine synaptogenesis especially relation new connection form daily electrotonic signalling along axon spine cause new connection make base kind spatial condition maybe electrical chemical attraction large heuristic   \n",
       "4  reason behind choose reporter gene experiment gene interest notice within example experiment class different reporter gene choose insert near gene interest prove whether gene express example may insert gene fluorescence next gene interest know transcribe whether organism cell fluorescent degree fluoresce notice experiment multiple version one case use fluorescent gene next different gene examp...   \n",
       "\n",
       "                                                         tags  \n",
       "0                                         [rna, biochemistry]  \n",
       "1                      [immunology, cell-biology, hematology]  \n",
       "2                      [dna, biochemistry, molecular-biology]  \n",
       "3                                              [neuroscience]  \n",
       "4  [molecular-genetics, gene-expression, experimental-design]  "
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change question df to only include top 100\n",
    "df_questions['tags'] = only_top_100\n",
    "df_questions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tokenize text & split/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "multilabel_binarizer = MultiLabelBinarizer()\n",
    "multilabel_binarizer.fit(df_questions.tags)\n",
    "labels = multilabel_binarizer.classes_\n",
    "\n",
    "maxlen = 180\n",
    "max_words = 5000\n",
    "tokenizer = Tokenizer(num_words=max_words, lower=True)\n",
    "tokenizer.fit_on_texts(df_questions.text)\n",
    "\n",
    "def get_features(text_series):\n",
    "    \"\"\"\n",
    "    transforms text data to feature_vectors that can be used in the ml model.\n",
    "    tokenizer must be available.\n",
    "    \"\"\"\n",
    "    sequences = tokenizer.texts_to_sequences(text_series)\n",
    "    return pad_sequences(sequences, maxlen=maxlen)\n",
    "\n",
    "\n",
    "def prediction_to_label(prediction):\n",
    "    tag_prob = [(labels[i], prob) for i, prob in enumerate(prediction.tolist())]\n",
    "    return dict(sorted(tag_prob, key=lambda kv: kv[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(set(labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10408, 180)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = get_features(df_questions.text)\n",
    "y = multilabel_binarizer.transform(df_questions.tags)\n",
    "print(x.shape)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=9000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imbalanced classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tag</th>\n",
       "      <th>count</th>\n",
       "      <th>class_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>human-biology</td>\n",
       "      <td>1448</td>\n",
       "      <td>14.783149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>genetics</td>\n",
       "      <td>1229</td>\n",
       "      <td>17.417413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>evolution</td>\n",
       "      <td>1159</td>\n",
       "      <td>18.469370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>biochemistry</td>\n",
       "      <td>984</td>\n",
       "      <td>21.754065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>molecular-biology</td>\n",
       "      <td>863</td>\n",
       "      <td>24.804171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Tag  count  class_weight\n",
       "298      human-biology   1448     14.783149\n",
       "253           genetics   1229     17.417413\n",
       "209          evolution   1159     18.469370\n",
       "51        biochemistry    984     21.754065\n",
       "398  molecular-biology    863     24.804171"
      ]
     },
     "execution_count": 522,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_common_tags['class_weight'] = len(df_tags) / most_common_tags['count']\n",
    "class_weight = {}\n",
    "for index, label in enumerate(labels): \n",
    "    class_weight[index] = most_common_tags[most_common_tags['Tag'] == label]['class_weight'].values[0]\n",
    "    \n",
    "most_common_tags.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build 1-d convolutional neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 180, 20)           100000    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 180, 20)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 178, 300)          18300     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_8 (Glob (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 148,400\n",
      "Trainable params: 148,400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6556 samples, validate on 729 samples\n",
      "Epoch 1/20\n",
      "6556/6556 [==============================] - 32s 5ms/step - loss: 14.5117 - categorical_accuracy: 0.0529 - val_loss: 7.2778 - val_categorical_accuracy: 0.0521\n",
      "Epoch 2/20\n",
      "6556/6556 [==============================] - 31s 5ms/step - loss: 7.9586 - categorical_accuracy: 0.0648 - val_loss: 7.2688 - val_categorical_accuracy: 0.0521\n",
      "Epoch 3/20\n",
      "6556/6556 [==============================] - 30s 5ms/step - loss: 7.9203 - categorical_accuracy: 0.0699 - val_loss: 7.2097 - val_categorical_accuracy: 0.0521\n",
      "Epoch 4/20\n",
      "6556/6556 [==============================] - 29s 4ms/step - loss: 7.8281 - categorical_accuracy: 0.0767 - val_loss: 7.0590 - val_categorical_accuracy: 0.0727\n",
      "Epoch 5/20\n",
      "6556/6556 [==============================] - 30s 5ms/step - loss: 7.5360 - categorical_accuracy: 0.1283 - val_loss: 6.7399 - val_categorical_accuracy: 0.1193\n",
      "Epoch 6/20\n",
      "6556/6556 [==============================] - 32s 5ms/step - loss: 6.9896 - categorical_accuracy: 0.1746 - val_loss: 6.1683 - val_categorical_accuracy: 0.1509\n",
      "Epoch 7/20\n",
      "6556/6556 [==============================] - 27s 4ms/step - loss: 6.4333 - categorical_accuracy: 0.2010 - val_loss: 5.8002 - val_categorical_accuracy: 0.2167\n",
      "Epoch 8/20\n",
      "6556/6556 [==============================] - 28s 4ms/step - loss: 5.9362 - categorical_accuracy: 0.2421 - val_loss: 5.5014 - val_categorical_accuracy: 0.2620\n",
      "Epoch 9/20\n",
      "6556/6556 [==============================] - 29s 4ms/step - loss: 5.5270 - categorical_accuracy: 0.2790 - val_loss: 5.4047 - val_categorical_accuracy: 0.2922\n",
      "Epoch 10/20\n",
      "6556/6556 [==============================] - 30s 5ms/step - loss: 5.1661 - categorical_accuracy: 0.3011 - val_loss: 5.3104 - val_categorical_accuracy: 0.2977\n",
      "Epoch 11/20\n",
      "6556/6556 [==============================] - 28s 4ms/step - loss: 4.8477 - categorical_accuracy: 0.3350 - val_loss: 5.3195 - val_categorical_accuracy: 0.3128\n",
      "Epoch 12/20\n",
      "6556/6556 [==============================] - 27s 4ms/step - loss: 4.5706 - categorical_accuracy: 0.3519 - val_loss: 5.2360 - val_categorical_accuracy: 0.2963\n",
      "Epoch 13/20\n",
      "6556/6556 [==============================] - 28s 4ms/step - loss: 4.3166 - categorical_accuracy: 0.3676 - val_loss: 5.2680 - val_categorical_accuracy: 0.3237\n",
      "Epoch 14/20\n",
      "6556/6556 [==============================] - 29s 4ms/step - loss: 4.0830 - categorical_accuracy: 0.3819 - val_loss: 5.3410 - val_categorical_accuracy: 0.3251\n",
      "Epoch 15/20\n",
      "6556/6556 [==============================] - 29s 4ms/step - loss: 3.8546 - categorical_accuracy: 0.3978 - val_loss: 5.3487 - val_categorical_accuracy: 0.3402\n",
      "Epoch 16/20\n",
      "6556/6556 [==============================] - 31s 5ms/step - loss: 3.6560 - categorical_accuracy: 0.4091 - val_loss: 5.4108 - val_categorical_accuracy: 0.3429\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Embedding, Flatten, GlobalMaxPool1D, Dropout, Conv1D\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "filter_length = 300\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, 20, input_length=maxlen))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Conv1D(filter_length, 3, padding='valid', activation='relu', strides=1))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['categorical_accuracy'])\n",
    "model.summary()\n",
    "\n",
    "callbacks = [\n",
    "    ReduceLROnPlateau(), \n",
    "    EarlyStopping(patience=4), \n",
    "    ModelCheckpoint(filepath='model-conv1d.h5', save_best_only=True)\n",
    "]\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    class_weight=class_weight,\n",
    "                    epochs=20,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3123/3123 [==============================] - 4s 1ms/step\n",
      "loss: 0.07273883121091129\n",
      "categorical_accuracy: 0.3105987832403473\n"
     ]
    }
   ],
   "source": [
    "import keras.models \n",
    "cnn_model = keras.models.load_model('model-conv1d.h5')\n",
    "metrics = cnn_model.evaluate(x_test, y_test)\n",
    "print(\"{}: {}\".format(model.metrics_names[0], metrics[0]))\n",
    "print(\"{}: {}\".format(model.metrics_names[1], metrics[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>OwnerUserId</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>Score</th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2010-07-19T19:14:44Z</td>\n",
       "      <td>272</td>\n",
       "      <td>The Two Cultures: statistics vs. machine learning?</td>\n",
       "      <td>&lt;p&gt;Last year, I read a blog post from &lt;a href=\"http://anyall.org/\"&gt;Brendan O'Connor&lt;/a&gt; entitled &lt;a href=\"http://anyall.org/blog/2008/12/statistics-vs-machine-learning-fight/\"&gt;\"Statistics vs. Machine Learning, fight!\"&lt;/a&gt; that discussed some of the differences between the two fields.  &lt;a href=\"http://andrewgelman.com/2008/12/machine_learnin/\"&gt;Andrew Gelman responded favorably to this&lt;/a&gt;:&lt;/p&gt;\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>59.0</td>\n",
       "      <td>2010-07-19T19:24:36Z</td>\n",
       "      <td>4</td>\n",
       "      <td>Forecasting demographic census</td>\n",
       "      <td>&lt;p&gt;What are some of the ways to forecast demographic census with some validation and calibration techniques?&lt;/p&gt;\\n\\n&lt;p&gt;Some of the concerns:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;Census blocks vary in sizes as rural\\nareas are a lot larger than condensed\\nurban areas. Is there a need to account for the area size difference?&lt;/li&gt;\\n&lt;li&gt;if let's say I have census data\\ndating back to 4 - 5 census periods,\\nhow far ca...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  OwnerUserId          CreationDate  Score  \\\n",
       "0   6          5.0  2010-07-19T19:14:44Z    272   \n",
       "1  21         59.0  2010-07-19T19:24:36Z      4   \n",
       "\n",
       "                                                Title  \\\n",
       "0  The Two Cultures: statistics vs. machine learning?   \n",
       "1                      Forecasting demographic census   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                              Body  \n",
       "0  <p>Last year, I read a blog post from <a href=\"http://anyall.org/\">Brendan O'Connor</a> entitled <a href=\"http://anyall.org/blog/2008/12/statistics-vs-machine-learning-fight/\">\"Statistics vs. Machine Learning, fight!\"</a> that discussed some of the differences between the two fields.  <a href=\"http://andrewgelman.com/2008/12/machine_learnin/\">Andrew Gelman responded favorably to this</a>:</p>\\...  \n",
       "1  <p>What are some of the ways to forecast demographic census with some validation and calibration techniques?</p>\\n\\n<p>Some of the concerns:</p>\\n\\n<ul>\\n<li>Census blocks vary in sizes as rural\\nareas are a lot larger than condensed\\nurban areas. Is there a need to account for the area size difference?</li>\\n<li>if let's say I have census data\\ndating back to 4 - 5 census periods,\\nhow far ca...  "
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_questions = pd.read_csv('../../Downloads/statsquestions/Questions.csv', encoding='iso-8859-1')\n",
    "df_tags = pd.read_csv('../../Downloads/statsquestions/Tags.csv', encoding='iso-8859-1')\n",
    "df_questions.head(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(85085, 6) (244228, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1315"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.shape(df_questions), np.shape(df_tags))\n",
    "len(set(df_tags.Tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     1315\n",
       "unique    1315\n",
       "top       mase\n",
       "freq         1\n",
       "Name: Tag, dtype: object"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_tags = df_tags.groupby(\"Tag\", sort='count').size().reset_index(name='count')\n",
    "grouped_tags.Tag.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 100\n",
    "grouped_tags = df_tags.groupby(\"Tag\").size().reset_index(name='count')\n",
    "most_common_tags = grouped_tags.nlargest(num_classes, columns=\"count\")\n",
    "df_tags.Tag = df_tags.Tag.apply(lambda tag : tag if tag in most_common_tags.Tag.values else None)\n",
    "df_tags = df_tags.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_tags)\n",
    "len(set(df_tags.Tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "def strip_html_tags(body):\n",
    "    regex = re.compile('<.*?>')\n",
    "    return re.sub(regex, '', body)\n",
    "\n",
    "df_questions['Body'] = df_questions['Body'].apply(strip_html_tags)\n",
    "df_questions['Text'] = df_questions['Title'] + ' ' + df_questions['Body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# denormalize tables\n",
    "\n",
    "def tags_for_question(question_id):\n",
    "    return df_tags[df_tags['Id'] == question_id].Tag.values\n",
    "\n",
    "def add_tags_column(row):\n",
    "    row['Tags'] = tags_for_question(row['Id'])\n",
    "    return row\n",
    "\n",
    "df_questions1 = df_questions.apply(add_tags_column, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85085, 8)"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(df_questions1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                                               [machine-learning]\n",
       "1                                                                                    [forecasting]\n",
       "2                                                                                       [bayesian]\n",
       "3                                            [hypothesis-testing, t-test, p-value, interpretation]\n",
       "4                                                                                    [correlation]\n",
       "5                                                                        [nonparametric, survival]\n",
       "6                                                                                    [time-series]\n",
       "7                                                                 [data-visualization, references]\n",
       "8                                                                               [machine-learning]\n",
       "9                                                                                     [references]\n",
       "10                                                                                [classification]\n",
       "11                                                                          [bayesian, references]\n",
       "12                                                                                              []\n",
       "13                                                                                   [time-series]\n",
       "14                                                                                   [sample-size]\n",
       "15                                                                       [r, time-series, poisson]\n",
       "16                                                                          [regression, outliers]\n",
       "17                                                                               [t-test, ordinal]\n",
       "18                                                                                    [references]\n",
       "19                                                                            [data-visualization]\n",
       "20                                     [standard-deviation, variance, anova, random-effects-model]\n",
       "21                                                                                      [modeling]\n",
       "22                                                                                    [clustering]\n",
       "23                                                                                    [estimation]\n",
       "24                                                [regression, distributions, data-transformation]\n",
       "25                                                              [r, clustering, feature-selection]\n",
       "26                                                     [self-study, econometrics, autocorrelation]\n",
       "27                                                                              [machine-learning]\n",
       "28                                                                                    [references]\n",
       "29                                 [classification, confidence-interval, nonparametric, bootstrap]\n",
       "                                                   ...                                            \n",
       "85055                                                                                           []\n",
       "85056                                                                   [statistical-significance]\n",
       "85057                                              [regression, multiple-regression, linear-model]\n",
       "85058                                                                           [categorical-data]\n",
       "85059                                                                       [variance, covariance]\n",
       "85060                                              [regression, multiple-regression, linear-model]\n",
       "85061                                                                                           []\n",
       "85062                                                                    [regression, interaction]\n",
       "85063                                                                               [optimization]\n",
       "85064                                                                                          [r]\n",
       "85065                                                          [r, regression, logistic, modeling]\n",
       "85066                                                                                [probability]\n",
       "85067                         [statistical-significance, normal-distribution, data-transformation]\n",
       "85068                                                                                          [r]\n",
       "85069                                                                               [optimization]\n",
       "85070                                                                                           []\n",
       "85071                                                          [machine-learning, neural-networks]\n",
       "85072                                                                                 [clustering]\n",
       "85073                                                                                          [r]\n",
       "85074                                                                                   [survival]\n",
       "85075                                                                                 [clustering]\n",
       "85076                                                [self-study, anova, generalized-linear-model]\n",
       "85077                                                                         [hypothesis-testing]\n",
       "85078                                                                                 [clustering]\n",
       "85079                                                                                 [regression]\n",
       "85080                                    [logistic, categorical-data, interaction, interpretation]\n",
       "85081                                                              [linear-model, goodness-of-fit]\n",
       "85082    [machine-learning, hypothesis-testing, statistical-significance, mathematical-statistics]\n",
       "85083                                                             [hypothesis-testing, self-study]\n",
       "85084                                                                         [hypothesis-testing]\n",
       "Name: Tags, Length: 85085, dtype: object"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 400)\n",
    "df_questions1[['Id', 'Text', 'Tags']].head(2)\n",
    "#pd.DataFrame(df_questions.tag, df_questions1.Tags)\n",
    "df_questions1.Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>OwnerUserId</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>Score</th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Text</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2010-07-19T19:14:44Z</td>\n",
       "      <td>272</td>\n",
       "      <td>The Two Cultures: statistics vs. machine learning?</td>\n",
       "      <td>Last year, I read a blog post from Brendan O'Connor entitled \"Statistics vs. Machine Learning, fight!\" that discussed some of the differences between the two fields.  Andrew Gelman responded favorably to this:\\n\\nSimon Blomberg: \\n\\n\\n  From R's fortunes\\n  package: To paraphrase provocatively,\\n  'machine learning is statistics minus\\n  any checking of models and\\n  assumptions'.\\n  -- Brian ...</td>\n",
       "      <td>The Two Cultures: statistics vs. machine learning? Last year, I read a blog post from Brendan O'Connor entitled \"Statistics vs. Machine Learning, fight!\" that discussed some of the differences between the two fields.  Andrew Gelman responded favorably to this:\\n\\nSimon Blomberg: \\n\\n\\n  From R's fortunes\\n  package: To paraphrase provocatively,\\n  'machine learning is statistics minus\\n  any c...</td>\n",
       "      <td>[machine-learning]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>59.0</td>\n",
       "      <td>2010-07-19T19:24:36Z</td>\n",
       "      <td>4</td>\n",
       "      <td>Forecasting demographic census</td>\n",
       "      <td>What are some of the ways to forecast demographic census with some validation and calibration techniques?\\n\\nSome of the concerns:\\n\\n\\nCensus blocks vary in sizes as rural\\nareas are a lot larger than condensed\\nurban areas. Is there a need to account for the area size difference?\\nif let's say I have census data\\ndating back to 4 - 5 census periods,\\nhow far can i forecast it into the\\nfutur...</td>\n",
       "      <td>Forecasting demographic census What are some of the ways to forecast demographic census with some validation and calibration techniques?\\n\\nSome of the concerns:\\n\\n\\nCensus blocks vary in sizes as rural\\nareas are a lot larger than condensed\\nurban areas. Is there a need to account for the area size difference?\\nif let's say I have census data\\ndating back to 4 - 5 census periods,\\nhow far ca...</td>\n",
       "      <td>[forecasting]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  OwnerUserId          CreationDate  Score  \\\n",
       "0   6          5.0  2010-07-19T19:14:44Z    272   \n",
       "1  21         59.0  2010-07-19T19:24:36Z      4   \n",
       "\n",
       "                                                Title  \\\n",
       "0  The Two Cultures: statistics vs. machine learning?   \n",
       "1                      Forecasting demographic census   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                              Body  \\\n",
       "0  Last year, I read a blog post from Brendan O'Connor entitled \"Statistics vs. Machine Learning, fight!\" that discussed some of the differences between the two fields.  Andrew Gelman responded favorably to this:\\n\\nSimon Blomberg: \\n\\n\\n  From R's fortunes\\n  package: To paraphrase provocatively,\\n  'machine learning is statistics minus\\n  any checking of models and\\n  assumptions'.\\n  -- Brian ...   \n",
       "1  What are some of the ways to forecast demographic census with some validation and calibration techniques?\\n\\nSome of the concerns:\\n\\n\\nCensus blocks vary in sizes as rural\\nareas are a lot larger than condensed\\nurban areas. Is there a need to account for the area size difference?\\nif let's say I have census data\\ndating back to 4 - 5 census periods,\\nhow far can i forecast it into the\\nfutur...   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                              Text  \\\n",
       "0  The Two Cultures: statistics vs. machine learning? Last year, I read a blog post from Brendan O'Connor entitled \"Statistics vs. Machine Learning, fight!\" that discussed some of the differences between the two fields.  Andrew Gelman responded favorably to this:\\n\\nSimon Blomberg: \\n\\n\\n  From R's fortunes\\n  package: To paraphrase provocatively,\\n  'machine learning is statistics minus\\n  any c...   \n",
       "1  Forecasting demographic census What are some of the ways to forecast demographic census with some validation and calibration techniques?\\n\\nSome of the concerns:\\n\\n\\nCensus blocks vary in sizes as rural\\nareas are a lot larger than condensed\\nurban areas. Is there a need to account for the area size difference?\\nif let's say I have census data\\ndating back to 4 - 5 census periods,\\nhow far ca...   \n",
       "\n",
       "                 Tags  \n",
       "0  [machine-learning]  \n",
       "1       [forecasting]  "
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_questions.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['hypothesis-testing', 't-test', 'p-value', 'interpretation'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_questions['Tags'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "multilabel_binarizer = MultiLabelBinarizer()\n",
    "multilabel_binarizer.fit(df_questions.Tags)\n",
    "labels = multilabel_binarizer.classes_\n",
    "\n",
    "maxlen = 180\n",
    "max_words = 5000\n",
    "tokenizer = Tokenizer(num_words=max_words, lower=True)\n",
    "tokenizer.fit_on_texts(df_questions.Text)\n",
    "\n",
    "def get_features(text_series):\n",
    "    \"\"\"\n",
    "    transforms text data to feature_vectors that can be used in the ml model.\n",
    "    tokenizer must be available.\n",
    "    \"\"\"\n",
    "    sequences = tokenizer.texts_to_sequences(text_series)\n",
    "    return pad_sequences(sequences, maxlen=maxlen)\n",
    "\n",
    "\n",
    "def prediction_to_label(prediction):\n",
    "    tag_prob = [(labels[i], prob) for i, prob in enumerate(prediction.tolist())]\n",
    "    return dict(sorted(tag_prob, key=lambda kv: kv[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_questions.Tags)\n",
    "#df_questions.Tags.ravel()\n",
    "df_questions.Tags.values.flatten()\n",
    "len(np.unique(np.concatenate(list(df_questions.Tags))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['algorithms', 'anova', 'arima', 'autocorrelation', 'bayesian',\n",
       "       'binary-data', 'binomial', 'bootstrap', 'cart', 'categorical-data',\n",
       "       'chi-squared', 'classification', 'clustering',\n",
       "       'conditional-probability', 'confidence-interval', 'correlation',\n",
       "       'covariance', 'cox-model', 'cross-validation', 'data-mining',\n",
       "       'data-transformation', 'data-visualization', 'dataset',\n",
       "       'deep-learning', 'distributions', 'econometrics', 'estimation',\n",
       "       'expected-value', 'experiment-design', 'factor-analysis',\n",
       "       'feature-selection', 'forecasting', 'generalized-linear-model',\n",
       "       'goodness-of-fit', 'hypothesis-testing', 'inference',\n",
       "       'interaction', 'interpretation', 'least-squares', 'linear-model',\n",
       "       'logistic', 'machine-learning', 'mathematical-statistics',\n",
       "       'matlab', 'maximum-likelihood', 'mcmc', 'mean', 'missing-data',\n",
       "       'mixed-model', 'model', 'model-selection', 'modeling',\n",
       "       'monte-carlo', 'multilevel-analysis', 'multiple-comparisons',\n",
       "       'multiple-regression', 'multivariate-analysis', 'neural-networks',\n",
       "       'nonlinear-regression', 'nonparametric', 'normal-distribution',\n",
       "       'optimization', 'ordinal', 'outliers', 'p-value', 'panel-data',\n",
       "       'pca', 'pdf', 'poisson', 'prediction', 'predictive-models',\n",
       "       'probability', 'proportion', 'python', 'r', 'random-effects-model',\n",
       "       'random-forest', 'random-variable', 'references', 'regression',\n",
       "       'regression-coefficients', 'repeated-measures', 'residuals',\n",
       "       'sample-size', 'sampling', 'self-study', 'simulation', 'spss',\n",
       "       'standard-deviation', 'standard-error', 'stata',\n",
       "       'statistical-significance', 'stochastic-processes', 'survey',\n",
       "       'survival', 'svm', 't-test', 'terminology', 'time-series',\n",
       "       'variance'], dtype=object)"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(85085, 180)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = get_features(df_questions.Text)\n",
    "y = multilabel_binarizer.transform(df_questions.Tags)\n",
    "print(x.shape)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=9000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tag</th>\n",
       "      <th>count</th>\n",
       "      <th>class_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>r</td>\n",
       "      <td>13236</td>\n",
       "      <td>11.552811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>regression</td>\n",
       "      <td>10959</td>\n",
       "      <td>13.953189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>machine-learning</td>\n",
       "      <td>6089</td>\n",
       "      <td>25.112991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220</th>\n",
       "      <td>time-series</td>\n",
       "      <td>5559</td>\n",
       "      <td>27.507285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>probability</td>\n",
       "      <td>4217</td>\n",
       "      <td>36.261086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Tag  count  class_weight\n",
       "986                  r  13236     11.552811\n",
       "1020        regression  10959     13.953189\n",
       "669   machine-learning   6089     25.112991\n",
       "1220       time-series   5559     27.507285\n",
       "946        probability   4217     36.261086"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_common_tags['class_weight'] = len(df_tags) / most_common_tags['count']\n",
    "class_weight = {}\n",
    "for index, label in enumerate(labels):\n",
    "    class_weight[index] = most_common_tags[most_common_tags['Tag'] == label]['class_weight'].values[0]\n",
    "    \n",
    "most_common_tags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 180, 20)           100000    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 180, 20)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 178, 300)          18300     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_5 (Glob (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 148,400\n",
      "Trainable params: 148,400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /Users/christinachang/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /Users/christinachang/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 61261 samples, validate on 6807 samples\n",
      "Epoch 1/20\n",
      "24736/61261 [===========>..................] - ETA: 2:45 - loss: 12.6320 - categorical_accuracy: 0.0464"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-279-83e07ea200e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                     \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                     callbacks=callbacks)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Embedding, Flatten, GlobalMaxPool1D, Dropout, Conv1D\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "filter_length = 300\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, 20, input_length=maxlen))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Conv1D(filter_length, 3, padding='valid', activation='relu', strides=1))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['categorical_accuracy'])\n",
    "model.summary()\n",
    "\n",
    "callbacks = [\n",
    "    ReduceLROnPlateau(), \n",
    "    EarlyStopping(patience=4), \n",
    "    ModelCheckpoint(filepath='model-conv1d.h5', save_best_only=True)\n",
    "]\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    class_weight=class_weight,\n",
    "                    epochs=20,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
